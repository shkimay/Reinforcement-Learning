{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YANnWUhTzj1M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class FrozenLake:\n",
        "  def __init__(self):\n",
        "    #Initialize the model (4 pts)\n",
        "    self.height = 4\n",
        "    self.width = 4\n",
        "    self.state_space = [(x,y) for x in range(self.height) for y in range(self.width)]         #Define state space\n",
        "    self.action_space = [0,1,2,3]        #Define action space (0: Up, 1: Down, 2: Left, 3: Right)\n",
        "    self.start_state = (0,0)           #Define start point\n",
        "    self.goal_state = (3,3)            #Define goal point\n",
        "    self.holes = [(0,2),(1,0),(2,1),(2,3)]               #Define holes\n",
        "    self.state = self.start_state\n",
        "\n",
        "  def reset(self):\n",
        "    self.state = self.start_state\n",
        "    return self.state\n",
        "\n",
        "  def step(self, action):\n",
        "    #Define reward-state transition (4 pts)\n",
        "    x = self.state[0]\n",
        "    y = self.state[1]\n",
        "\n",
        "    if action == 0:\n",
        "      x = max(x-1,0)               #state transition after choosing Up\n",
        "\n",
        "\n",
        "    elif action == 1:\n",
        "      x = min(x+1,3)             #state transition after choosing Down\n",
        "\n",
        "\n",
        "    elif action == 2:\n",
        "      y = max(y-1,0)             #state transition after choosing Left\n",
        "\n",
        "\n",
        "    elif action == 3:\n",
        "      y = min(y+1,3)            #state transition after choosing Right\n",
        "\n",
        "    self.state = (x, y)\n",
        "\n",
        "    if self.state in self.holes:\n",
        "      return self.state, -2, True                     #(terminal state, reward, done)\n",
        "\n",
        "    elif self.state == self.goal_state:\n",
        "      return  self.state, 2, True                     #(terminal state, reward, done)\n",
        "\n",
        "    else:\n",
        "      return  self.state, 0, False                      #(non-terminal state, reward, done)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def equiprobable_random_policy(state):\n",
        "  return np.random.choice([0, 1, 2, 3])"
      ],
      "metadata": {
        "id": "xt5QMNAD1DtW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate 10 episodes (2 pts) - Do not change, just run\n",
        "np.random.seed(1)\n",
        "env = FrozenLake()\n",
        "\n",
        "i = 1\n",
        "while i <= 10:\n",
        "  episode = []\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  while (not done):\n",
        "    action = equiprobable_random_policy(state)\n",
        "    next_state, reward, done = env.step(action)\n",
        "    episode.append((state, action, reward))\n",
        "    state = next_state\n",
        "  episode.append((state, 'Terminal'))\n",
        "  print('Episode', i, ':', episode)\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "lUeOyw-z1LOh",
        "outputId": "06ec7542-723d-40ff-f03c-49407e5247ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1 : [((0, 0), 1, -2), ((1, 0), 'Terminal')]\n",
            "Episode 2 : [((0, 0), 3, 0), ((0, 1), 0, 0), ((0, 1), 0, 0), ((0, 1), 3, -2), ((0, 2), 'Terminal')]\n",
            "Episode 3 : [((0, 0), 1, -2), ((1, 0), 'Terminal')]\n",
            "Episode 4 : [((0, 0), 3, 0), ((0, 1), 1, 0), ((1, 1), 3, 0), ((1, 2), 0, -2), ((0, 2), 'Terminal')]\n",
            "Episode 5 : [((0, 0), 0, 0), ((0, 0), 1, -2), ((1, 0), 'Terminal')]\n",
            "Episode 6 : [((0, 0), 0, 0), ((0, 0), 3, 0), ((0, 1), 1, 0), ((1, 1), 0, 0), ((0, 1), 2, 0), ((0, 0), 1, -2), ((1, 0), 'Terminal')]\n",
            "Episode 7 : [((0, 0), 2, 0), ((0, 0), 0, 0), ((0, 0), 2, 0), ((0, 0), 1, -2), ((1, 0), 'Terminal')]\n",
            "Episode 8 : [((0, 0), 2, 0), ((0, 0), 0, 0), ((0, 0), 3, 0), ((0, 1), 0, 0), ((0, 1), 2, 0), ((0, 0), 0, 0), ((0, 0), 1, -2), ((1, 0), 'Terminal')]\n",
            "Episode 9 : [((0, 0), 2, 0), ((0, 0), 2, 0), ((0, 0), 0, 0), ((0, 0), 3, 0), ((0, 1), 3, -2), ((0, 2), 'Terminal')]\n",
            "Episode 10 : [((0, 0), 1, -2), ((1, 0), 'Terminal')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax(arr):\n",
        "    return np.random.choice([idx for idx in range(len(arr)) if arr[idx] == arr.max()])"
      ],
      "metadata": {
        "id": "C2Cmq7Kk1g6I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MC_Control:\n",
        "  def __init__(self, env, gamma = 0.9, epsilon = 0.2):\n",
        "    #Initialize the model (2 pts)\n",
        "    self.env = env\n",
        "    self.gamma = gamma\n",
        "    self.epsilon = epsilon\n",
        "    self.q_table = {state: np.zeros(len(self.env.action_space)) for state in self.env.state_space}\n",
        "    self.returns = {state: {action: 0 for action in self.env.action_space} for state in self.env.state_space}\n",
        "    self.visits = {state: {action: 0 for action in self.env.action_space} for state in self.env.state_space}\n",
        "\n",
        "  #Define epsilon-greedy (2 pts)\n",
        "  def epsilon_greedy(self, state):\n",
        "    if np.random.rand() < self.epsilon:\n",
        "      return np.random.choice(self.env.action_space)\n",
        "    else:\n",
        "      return argmax(self.q_table[state])\n",
        "\n",
        "  #Generate episodes (2 pts)\n",
        "  def generate_episode(self):\n",
        "    episode = []\n",
        "    state = self.env.reset()\n",
        "    done = False\n",
        "\n",
        "    while (not done):\n",
        "      action = self.epsilon_greedy(state)\n",
        "      next_state, reward, done = self.env.step(action)\n",
        "      episode.append((state, action, reward))\n",
        "      state = next_state\n",
        "    return episode\n",
        "\n",
        "\n",
        "  #Update first-visit Q table (10 pts)\n",
        "  def update_q(self, episode):\n",
        "    G = 0\n",
        "\n",
        "    first_visit = {}\n",
        "    # Store first visit of (s, a) in first_visit dictionary using for statement\n",
        "    for t, (state, action, reward) in enumerate(episode):\n",
        "      if state not in first_visit:\n",
        "            first_visit[state] = {}\n",
        "      if action not in first_visit[state]:\n",
        "            first_visit[state][action] = t\n",
        "\n",
        "    for t in range(len(episode)-1, -1, -1):\n",
        "      state, action, reward = episode[t]\n",
        "      G = reward + self.gamma*G\n",
        "\n",
        "      # Update q_table if (s, a) is the first-visit\n",
        "      if first_visit[state][action] == t:\n",
        "        self.returns[state][action] += G\n",
        "        self.visits[state][action] += 1\n",
        "        self.q_table[state][action] = self.returns[state][action]/self.visits[state][action]\n",
        "\n",
        "  def control(self, episodes=10000):\n",
        "    for i in range(1, episodes+1):\n",
        "      if i % int(episodes/10) == 0:\n",
        "        print('Episode ', i, '/', episodes, ': ', '[', '*'*int(i/(episodes/10)), '-'*int((episodes - i)/(episodes/10)), ']')\n",
        "      episode = self.generate_episode()\n",
        "      self.update_q(episode)\n",
        "\n",
        "    policy = {state: argmax(actions) for state, actions in self.q_table.items()}\n",
        "    return policy, self.q_table"
      ],
      "metadata": {
        "id": "6OXrNSUt1Vr7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = FrozenLake()\n",
        "\n",
        "MC_FrozenLake = MC_Control(env)\n",
        "opt_policy, q_table = MC_FrozenLake.control()"
      ],
      "metadata": {
        "id": "2L4ISmeV4Di1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578bbc97-8da9-46f8-b3f1-ca8e543b8aee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode  1000 / 10000 :  [ * --------- ]\n",
            "Episode  2000 / 10000 :  [ ** -------- ]\n",
            "Episode  3000 / 10000 :  [ *** ------- ]\n",
            "Episode  4000 / 10000 :  [ **** ------ ]\n",
            "Episode  5000 / 10000 :  [ ***** ----- ]\n",
            "Episode  6000 / 10000 :  [ ****** ---- ]\n",
            "Episode  7000 / 10000 :  [ ******* --- ]\n",
            "Episode  8000 / 10000 :  [ ******** -- ]\n",
            "Episode  9000 / 10000 :  [ ********* - ]\n",
            "Episode  10000 / 10000 :  [ **********  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimal policy - Do not change, just run(4 pts)\n",
        "policy = [[0 for _ in range(4)] for _ in range(4)]\n",
        "\n",
        "for state, action in opt_policy.items():\n",
        "  if action == 0:\n",
        "    policy[state[0]][state[1]] = '^'\n",
        "  elif action == 1:\n",
        "    policy[state[0]][state[1]] = 'v'\n",
        "  elif action == 2:\n",
        "    policy[state[0]][state[1]] = '<'\n",
        "  elif action == 3:\n",
        "    policy[state[0]][state[1]] = '>'\n",
        "\n",
        "policy[0][2], policy[1][0], policy[2][1], policy[2][3] = 'H', 'H', 'H', 'H'\n",
        "policy[3][3] = 'G'\n",
        "policy"
      ],
      "metadata": {
        "id": "uVPGcQGF4HVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991a0a19-e80a-4db6-eb1b-8bbff44151bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['^', '<', 'H', '>'],\n",
              " ['H', '^', '>', '<'],\n",
              " ['^', 'H', '^', 'H'],\n",
              " ['<', '>', 'v', 'G']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}