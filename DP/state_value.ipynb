{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dvuc7lIzk11e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "#define the transition (default size = 5x5)\n",
        "def next_state_reward(state, action, height = 5, width = 5):\n",
        "  action_move = [(-1, 0), (1, 0), (0, -1), (0, 1)] #4 possible actions -  0: Up / 1: Down / 2: Left / 3: Right\n",
        "\n",
        "  #state transition: states = (height, width)\n",
        "  state[0] += action_move[action][0]\n",
        "  state[1] += action_move[action][1]\n",
        "\n",
        "  #treating some blocked moves\n",
        "  if state[0] < 0:\n",
        "    state[0] = 0\n",
        "  elif state[0] >  height-1:\n",
        "    state[0] = height-1\n",
        "  if state[1] < 0:\n",
        "    state[1] = 0\n",
        "  elif state[1] > width-1:\n",
        "    state[1] = width-1\n",
        "\n",
        "  #return the new state according to the selected action and reward = -1\n",
        "  return [state[0], state[1]], -1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mysterious_state_reward(state, action, height = 5, width = 5):\n",
        "  action_move = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
        "\n",
        "  mys = []\n",
        "\n",
        "  mys_1 = [1,3]\n",
        "  mys_2 = [0,3]\n",
        "\n",
        "  if state in ([0,2] or [2,1]):\n",
        "    mys = mys_1\n",
        "  else:\n",
        "    mys = mys_2\n",
        "\n",
        "  a = random.choice(mys)\n",
        "  state[0] += action_move[a][0]\n",
        "  state[1] += action_move[a][1]\n",
        "\n",
        "  if state[0] < 0:\n",
        "    state[0] = 0\n",
        "  elif state[0] >  height-1:\n",
        "    state[0] = height-1\n",
        "  if state[1] < 0:\n",
        "    state[1] = 0\n",
        "  elif state[1] > width-1:\n",
        "    state[1] = width-1\n",
        "\n",
        "  return [state[0], state[1]], 2"
      ],
      "metadata": {
        "id": "Qh_myXUVv3O9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_evaluation(action, policy, height = 5, width = 5, theta=1e-5, gamma=0.9):\n",
        "  #initialize state value function\n",
        "  value_table = np.zeros(shape=(height, width))\n",
        "\n",
        "  #two-array version (try in-place version by yourself)\n",
        "  iter = 0\n",
        "  while iter<2000:\n",
        "    #update the new state value function\n",
        "    next_value_table = np.zeros(shape=(height, width))\n",
        "    delta = 0\n",
        "    for i in range(height):\n",
        "      for j in range(width):\n",
        "\n",
        "        #always assign 0 to the terminal states\n",
        "        if ((i == 0) and (j == 0)) or ((i == height-1) and (j == height-1)):\n",
        "          value_iter = 0\n",
        "\n",
        "        else:\n",
        "          #update the non-terminal states using the Bellman equation\n",
        "          value_iter = 0\n",
        "\n",
        "          for act in action:\n",
        "            if [i,j] in [[0,2],[2,1],[3,3]]:\n",
        "                transition_prob = 0.5\n",
        "                next_s, r = mysterious_state_reward([i,j], act)\n",
        "\n",
        "            else:\n",
        "                transition_prob = 1 #deterministic\n",
        "                next_s, r = next_state_reward([i,j], act)\n",
        "            value_iter += policy[i][j][act]*transition_prob*(r + gamma*value_table[next_s[0]][next_s[1]])\n",
        "\n",
        "          #deterministic state transition (do not consider the transition probability in this case)\n",
        "          # for act in action:\n",
        "          #   next_s, r = next_state_reward([i,j], act)\n",
        "          #   value_iter += policy[i][j][act]*transition_prob*(r + gamma*value_table[next_s[0]][next_s[1]])\n",
        "\n",
        "        #update the state value function\n",
        "        next_value_table[i][j] = round(value_iter, 3)\n",
        "\n",
        "        #compare the error and the error bound\n",
        "        delta = max(delta, abs(next_value_table[i][j] - value_table[i][j]))\n",
        "\n",
        "    value_table = next_value_table\n",
        "    iter += 1\n",
        "\n",
        "    #termination condition\n",
        "    if delta < theta:\n",
        "      # print('Final results ({} iterations): \\n {}'.format(iter, next_value_table))\n",
        "      break\n",
        "\n",
        "    # print the results\n",
        "    iter_visual = [1, 2, 10, 50] + [n*100 for n in range(20)]\n",
        "    if iter in iter_visual:\n",
        "      print('iteration {}: \\n {}'.format(iter, next_value_table))\n",
        "\n",
        "  return next_value_table"
      ],
      "metadata": {
        "id": "CrohkgCek_C5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grid environment\n",
        "grid_height, grid_width = 5, 5 #5x5 gridworld\n",
        "action = [0, 1, 2, 3] #0: up / 1: down / 2: left / 3: right\n",
        "\n",
        "#policy initialization\n",
        "policy = np.zeros(shape=(grid_height, grid_width, len(action)))\n",
        "\n",
        "#random equiprobable policy\n",
        "for i in range(grid_height):\n",
        "  for j in range(grid_width):\n",
        "    for k in range(len(action)):\n",
        "      if ((i == 0) and (j == 0)) or ((i == grid_height-1) and (j == grid_height-1)):\n",
        "        policy[i][j][k] = 0\n",
        "      else:\n",
        "        policy[i][j][k] = 0.25\n",
        "\n",
        "\n",
        "state_value = policy_evaluation(action, policy)\n",
        "# in_place_state_value = policy_evaluation_in_place(action, policy)\n",
        "print('Vㅠ(s):',state_value)\n",
        "# print('V(s):',in_place_state_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ryB5kDZlBra",
        "outputId": "e5edec77-e0f4-47ab-a192-197303a4c1fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1: \n",
            " [[ 0. -1.  1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1.]\n",
            " [-1.  1. -1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.]\n",
            " [-1. -1. -1. -1.  0.]]\n",
            "iteration 2: \n",
            " [[ 0.    -1.225  1.225 -1.45  -1.9  ]\n",
            " [-1.675 -1.45  -1.45  -1.9   -1.9  ]\n",
            " [-1.45   0.55  -1.45  -1.45  -1.9  ]\n",
            " [-1.9   -1.45  -1.45   0.55  -1.225]\n",
            " [-1.9   -1.9   -1.9   -1.225  0.   ]]\n",
            "iteration 10: \n",
            " [[ 0.    -2.14   0.564 -4.026 -5.322]\n",
            " [-3.118 -3.029 -3.378 -4.619 -5.255]\n",
            " [-3.617 -0.441 -3.45  -3.821 -4.502]\n",
            " [-4.947 -4.058 -3.693 -0.509 -2.652]\n",
            " [-5.622 -5.182 -4.444 -2.637  0.   ]]\n",
            "iteration 50: \n",
            " [[ 0.    -2.328 -0.661 -4.704 -6.26 ]\n",
            " [-3.44  -3.422 -3.821 -5.372 -6.117]\n",
            " [-4.213 -0.599 -4.034 -4.364 -5.206]\n",
            " [-5.85  -4.834 -4.267 -0.808 -2.985]\n",
            " [-6.724 -6.137 -5.167 -2.972  0.   ]]\n",
            "iteration 100: \n",
            " [[ 0.    -1.984  1.513 -4.367 -6.213]\n",
            " [-3.461 -3.267 -3.572 -5.234 -6.143]\n",
            " [-4.189 -0.564 -3.947 -4.359 -5.205]\n",
            " [-5.847 -4.82  -4.238 -0.658 -2.949]\n",
            " [-6.726 -6.135 -5.176 -2.94   0.   ]]\n",
            "iteration 200: \n",
            " [[ 0.    -2.337  0.326 -4.713 -6.179]\n",
            " [-3.47  -3.186 -3.953 -5.187 -6.139]\n",
            " [-4.158 -0.784 -3.903 -4.399 -5.216]\n",
            " [-5.85  -4.796 -4.277 -0.515 -2.992]\n",
            " [-6.727 -6.136 -5.195 -2.984  0.   ]]\n",
            "iteration 300: \n",
            " [[ 0.    -1.865  0.964 -4.236 -6.154]\n",
            " [-3.433 -3.162 -3.452 -5.186 -6.104]\n",
            " [-4.146 -0.597 -3.902 -4.424 -5.231]\n",
            " [-5.843 -4.78  -4.335 -0.836 -3.067]\n",
            " [-6.712 -6.133 -5.188 -3.056  0.   ]]\n",
            "iteration 400: \n",
            " [[ 0.    -2.299  0.345 -4.681 -6.187]\n",
            " [-3.455 -3.201 -3.896 -5.194 -6.13 ]\n",
            " [-4.177 -0.693 -3.907 -4.41  -5.21 ]\n",
            " [-5.858 -4.798 -4.305 -0.498 -3.019]\n",
            " [-6.727 -6.137 -5.169 -3.005  0.   ]]\n",
            "iteration 500: \n",
            " [[ 0.    -2.394  0.263 -4.792 -6.266]\n",
            " [-3.448 -3.322 -3.94  -5.318 -6.154]\n",
            " [-4.166 -0.621 -3.949 -4.363 -5.21 ]\n",
            " [-5.851 -4.78  -4.251 -0.958 -2.955]\n",
            " [-6.721 -6.143 -5.156 -2.94   0.   ]]\n",
            "iteration 600: \n",
            " [[ 0.    -2.206 -0.038 -4.553 -6.081]\n",
            " [-3.406 -3.152 -3.782 -5.129 -6.055]\n",
            " [-4.171 -0.565 -3.914 -4.284 -5.216]\n",
            " [-5.841 -4.819 -4.215 -0.675 -2.958]\n",
            " [-6.723 -6.138 -5.197 -2.952  0.   ]]\n",
            "iteration 700: \n",
            " [[ 0.    -2.288 -0.066 -4.711 -6.299]\n",
            " [-3.49  -3.308 -3.911 -5.295 -6.225]\n",
            " [-4.199 -0.679 -3.97  -4.551 -5.248]\n",
            " [-5.858 -4.817 -4.405 -0.511 -3.094]\n",
            " [-6.723 -6.155 -5.189 -3.079  0.   ]]\n",
            "iteration 800: \n",
            " [[ 0.    -2.331 -0.131 -4.737 -6.304]\n",
            " [-3.463 -3.374 -3.872 -5.37  -6.178]\n",
            " [-4.186 -0.558 -3.999 -4.413 -5.231]\n",
            " [-5.855 -4.81  -4.292 -0.498 -2.998]\n",
            " [-6.734 -6.15  -5.178 -2.984  0.   ]]\n",
            "iteration 900: \n",
            " [[ 0.    -2.325 -0.113 -4.699 -6.24 ]\n",
            " [-3.454 -3.348 -3.869 -5.312 -6.134]\n",
            " [-4.176 -0.709 -3.978 -4.399 -5.198]\n",
            " [-5.838 -4.806 -4.284 -0.65  -2.987]\n",
            " [-6.716 -6.139 -5.172 -2.98   0.   ]]\n",
            "iteration 1000: \n",
            " [[ 0.    -2.175  0.037 -4.566 -6.249]\n",
            " [-3.463 -3.285 -3.747 -5.277 -6.159]\n",
            " [-4.154 -0.642 -3.912 -4.414 -5.189]\n",
            " [-5.845 -4.771 -4.288 -0.791 -2.983]\n",
            " [-6.723 -6.14  -5.154 -2.972  0.   ]]\n",
            "iteration 1100: \n",
            " [[ 0.    -2.177  0.013 -4.545 -6.211]\n",
            " [-3.433 -3.33  -3.695 -5.302 -6.1  ]\n",
            " [-4.167 -0.444 -3.969 -4.358 -5.195]\n",
            " [-5.833 -4.794 -4.258 -0.811 -2.982]\n",
            " [-6.716 -6.127 -5.169 -2.976  0.   ]]\n",
            "iteration 1200: \n",
            " [[ 0.    -2.288 -0.577 -4.679 -6.242]\n",
            " [-3.473 -3.283 -3.88  -5.257 -6.166]\n",
            " [-4.17  -0.656 -3.93  -4.422 -5.194]\n",
            " [-5.84  -4.795 -4.285 -0.803 -2.983]\n",
            " [-6.723 -6.135 -5.166 -2.976  0.   ]]\n",
            "iteration 1300: \n",
            " [[ 0.    -2.397  0.26  -4.794 -6.276]\n",
            " [-3.452 -3.323 -3.931 -5.357 -6.154]\n",
            " [-4.164 -0.615 -3.993 -4.386 -5.254]\n",
            " [-5.854 -4.799 -4.273 -0.847 -3.005]\n",
            " [-6.729 -6.141 -5.198 -2.989  0.   ]]\n",
            "iteration 1400: \n",
            " [[ 0.    -2.086 -0.47  -4.497 -6.241]\n",
            " [-3.459 -3.261 -3.695 -5.264 -6.183]\n",
            " [-4.193 -0.56  -3.984 -4.396 -5.275]\n",
            " [-5.853 -4.836 -4.269 -0.544 -2.996]\n",
            " [-6.728 -6.151 -5.222 -2.98   0.   ]]\n",
            "iteration 1500: \n",
            " [[ 0.    -2.255 -1.092 -4.654 -6.246]\n",
            " [-3.451 -3.282 -3.831 -5.284 -6.165]\n",
            " [-4.168 -0.629 -3.952 -4.413 -5.231]\n",
            " [-5.842 -4.801 -4.291 -0.345 -3.005]\n",
            " [-6.72  -6.144 -5.184 -2.99   0.   ]]\n",
            "iteration 1600: \n",
            " [[ 0.    -2.308 -0.568 -4.703 -6.211]\n",
            " [-3.46  -3.244 -3.917 -5.242 -6.164]\n",
            " [-4.207 -0.549 -3.979 -4.419 -5.274]\n",
            " [-5.869 -4.844 -4.314 -0.696 -3.03 ]\n",
            " [-6.734 -6.164 -5.223 -3.015  0.   ]]\n",
            "iteration 1700: \n",
            " [[ 0.    -2.285 -0.542 -4.656 -6.165]\n",
            " [-3.459 -3.217 -3.886 -5.196 -6.122]\n",
            " [-4.207 -0.619 -3.95  -4.419 -5.238]\n",
            " [-5.873 -4.836 -4.328 -0.366 -3.043]\n",
            " [-6.733 -6.153 -5.203 -3.03   0.   ]]\n",
            "iteration 1800: \n",
            " [[ 0.    -2.327 -0.145 -4.703 -6.199]\n",
            " [-3.433 -3.275 -3.872 -5.267 -6.113]\n",
            " [-4.177 -0.67  -3.966 -4.358 -5.225]\n",
            " [-5.841 -4.814 -4.259 -0.829 -2.993]\n",
            " [-6.724 -6.133 -5.187 -2.982  0.   ]]\n",
            "iteration 1900: \n",
            " [[ 0.    -2.353 -0.139 -4.714 -6.175]\n",
            " [-3.456 -3.246 -3.943 -5.229 -6.118]\n",
            " [-4.179 -0.639 -3.972 -4.36  -5.237]\n",
            " [-5.848 -4.83  -4.256 -0.85  -2.975]\n",
            " [-6.717 -6.143 -5.218 -2.969  0.   ]]\n",
            "Vㅠ(s): [[ 0.    -1.962  1.478 -4.344 -6.187]\n",
            " [-3.424 -3.251 -3.522 -5.234 -6.116]\n",
            " [-4.172 -0.514 -3.943 -4.436 -5.218]\n",
            " [-5.838 -4.809 -4.334 -0.662 -3.067]\n",
            " [-6.722 -6.136 -5.179 -3.054  0.   ]]\n"
          ]
        }
      ]
    }
  ]
}